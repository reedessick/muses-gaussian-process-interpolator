#!/usr/bin/env python3

"""a simple test of the interpolator
"""
__author__ = "Reed Essick (reed.essick@gmail.com), Ziyuan Zhang (ziyuan.z@wustl.edu)"

#-------------------------------------------------

import time
import os

import numpy as np
import h5py

from argparse import ArgumentParser

### non-standard libraries
import mgpi

#-------------------------------------------------

DEFAULT_DOWNSAMPLE = 1
DEFAULT_MAX_TEMPERATURE = 400.0

#-------------------------------------------------

parser = ArgumentParser()

parser.add_argument('eos_path', type=str)

parser.add_argument('--max-temperature', default=DEFAULT_MAX_TEMPERATURE, type=float,
    help='only consider data below this temperature. Should be specified in MeV. \
DEFAULT=%.3f MeV' % DEFAULT_MAX_TEMPERATURE)

parser.add_argument('--downsample', default=DEFAULT_DOWNSAMPLE, type=int,
    help='downsample the input data to keep only 1 sample out of this many. \
DEFAULT=%d' % DEFAULT_DOWNSAMPLE )

parser.add_argument('--fix', default=[], type=str, nargs=2, action='append')

parser.add_argument('--temperature', default=mgpi.DEFAULT_TEMPERATURE, type=int)
parser.add_argument('--num-burnin', default=mgpi.DEFAULT_NUM_BURNIN, type=int)
parser.add_argument('--num-samples', default=mgpi.DEFAULT_NUM_SAMPLES, type=int)
parser.add_argument('--num-walkers', default=mgpi.DEFAULT_NUM_WALKERS, type=int)

parser.add_argument('--num-neighbors', default=mgpi.DEFAULT_NUM_NEIGHBORS, type=int)
parser.add_argument('--order-by-index', default=mgpi.DEFAULT_ORDER_BY_INDEX, type=int)

parser.add_argument('--skip', default=[], type=str, action='append',
    help='skip this sampler. Can be repeated')

parser.add_argument('-v', '--verbose', default=False, action='store_true')
parser.add_argument('--time-execution', default=False, action='store_true')

args = parser.parse_args()

args.verbose |= args.time_execution

fixed = dict([(key, float(val)) for key, val in args.fix])

#-------------------------------------------------

# let's build an interpolator over the speed of sound using half the points available
# the speed of sound seems to have the most interesting behavior, or at least features
# that might be the hardest for the GP to emulate accruately

if args.verbose:
    print('loading data from : '+args.eos_path)
    if args.time_execution:
        t0 = time.time()

# load sample data
data = np.genfromtxt(args.eos_path, delimiter=',', names=True)

# grab the relevant data
baryon_chemical_potential = data['muB_MeV']
temperature = data['T_MeV']
speed_of_sound = data['speed_of_sound']

### reshape
num = len(np.unique(baryon_chemical_potential))
shape = (len(data)//num, num)

if args.verbose:
    print('    found data with shape :', shape)
    if args.time_execution:
        print('    time : %.6f sec' % (time.time()-t0))

baryon_chemical_potential = baryon_chemical_potential.reshape(shape)
temperature = temperature.reshape(shape)
speed_of_sound = speed_of_sound.reshape(shape)

### throw away the boring part of the EoS

keep = temperature[:,0] <= args.max_temperature

baryon_chemical_potential = baryon_chemical_potential[keep,:]
temperature = temperature[keep,:]
speed_of_sound = speed_of_sound[keep,:]

if args.verbose:
    print('    downselected data to temperatures below %.3f MeV; retained shape : %s' % \
        (args.max_temperature, np.shape(speed_of_sound)))

### now decimate the data so that the covariance matrices we build fit in memory

baryon_chemical_potential = baryon_chemical_potential[::args.downsample, ::args.downsample]
temperature = temperature[::args.downsample, ::args.downsample]
speed_of_sound = speed_of_sound[::args.downsample, ::args.downsample]

if args.verbose:
    print('    further downselected data to shape :', np.shape(speed_of_sound))

#------------------------

# let's then divide this into training and testing sets
# we divid the grid in the following way: (o --> training set, x --> test set)
#     o o o o o
#     o x o x o
#     o o o o o
#     o x o x o
#     o o o o o

if args.verbose:
    print('formatting training and test sets')
    if args.time_execution:
        t0 = time.time()

source_x = []
source_f = []
target_x = []
target_f = []

for ind in range(len(speed_of_sound)):
    offset = ind % 2 ### figure out whether this is an odd or an even row

    if offset: # an odd row, so only take every other sample for training set
        # grab the training data
        source_x.append(np.transpose([baryon_chemical_potential[ind, ::2], temperature[ind, ::2]]))
        source_f.append(speed_of_sound[ind, ::2])

        # grab the test data
        target_x.append(np.transpose([baryon_chemical_potential[ind, 1::2], temperature[ind, 1::2]]))
        target_f.append(speed_of_sound[ind,1::2])

    else: # an even row, so grab everything
        # grab the training data
        source_x.append(np.transpose([baryon_chemical_potential[ind,:], temperature[ind,:]]))
        source_f.append(speed_of_sound[ind,:])

source_x = np.concatenate(tuple(source_x))
source_f = np.concatenate(tuple(source_f))

target_x = np.concatenate(tuple(target_x))
target_f = np.concatenate(tuple(target_f))

if args.verbose:
    print('    selected:\n        %d training points\n        %d test points'%(len(source_x), len(target_x)))
    if args.time_execution:
        print('    time : %.6f sec' % (time.time()-t0))

#------------------------

if args.verbose:
    print('estimating appropriate hyperparameters and constructing kernel')
    if args.time_execution:
        t0 = time.time()

# now, let's guess at appropriate hyperparameters
ave = np.mean(source_f)       ### mean of the process

### FIXME! pick these based on maximizing the marginal likelihood for (source_f, source_x)

sigma = np.std(source_f) * 1.5  ### variance based on spread of the function

lengths = [                   ### based on the average grid spacing
    np.mean(np.diff(baryon_chemical_potential[0,:])) * 2.0,
    np.mean(np.diff(temperature[:,0])) * 2.0,
]

# construct a kernel
kernel = mgpi.CombinedKernel(
    mgpi.SquaredExponentialKernel(sigma, *lengths),
    mgpi.WhiteNoiseKernel(sigma/1000), # a small white noise component for numerical stability
)

if args.verbose:
    print(kernel)

# construct a general interpolator
basic = mgpi.Interpolator(kernel)

nngp = mgpi.NearestNeighborInterpolator(
    kernel,
    num_neighbors=args.num_neighbors,
    order_by_index=args.order_by_index,
)

if args.time_execution:
    print('    time : %.6f sec' % (time.time()-t0))

#-------------------------------------------------
#
# draw hyperparameter samples
#
#-------------------------------------------------

if fixed:
    print('\n>>> fixed:')
    for key, val in fixed.items():
        print('    %s = %.3e' % (key, val))

# define a basic prior
bounds = [
    (0.01, 2.0),  # sigma_0 --> SquaredExponentialKernel
    (1.0, 200.0),  # length0_0 --> SquaredExponentialKernel (baryon_chemical_potential)
    (1.0, 15.0),  # length1_0 --> SquaredExponentialKernel  (temperature)
    (1e-4, 1e-3), # sigma_1 --> WhiteNoiseKernel
]
bounds = [(key, val) for key, val in zip(kernel._params, bounds) if (key not in fixed)]

print('>>> logprior:')
for key, (m, M) in bounds:
    print('    %.3e <= %s <= %.3e' % (m, key, M))

def logprior(params):
    for p, (_, (m, M)) in zip(params, bounds):
        if (p < m) or (M < p):
            return -np.infty
    else:
        return 0.0

#------------------------

print("\n>>> sampling hyperparameters from distribution defined by loglikelihood")

for interp, name in [
        (basic, 'Interpolator'),
        (nngp, 'NearestNeighborInterpolator'),
    ]:

    if name in args.skip:
        print('>>> skipping '+name)
        continue

    print('>>> '+name)

    # obtain samples
    samples, logprob, sampler = interp.sample_kernel(
        source_x,
        source_f,
        logprior=logprior,
        fixed=fixed,
        temperature=args.temperature,
        num_burnin=args.num_burnin,
        num_samples=args.num_samples,
        num_walkers=args.num_walkers,
        Verbose=args.time_execution,
    )

    # save samples to disk
    outpath = os.path.basename(__file__) + '-%s-samples.hdf' % name
    if args.verbose:
        print('saving samples to: '+outpath)
    with h5py.File(outpath, 'w') as obj:

        # store command-line options
        grp = obj.create_group('command-line-options')

        grp.create_dataset(name='num_neighbors', data=args.num_neighbors)
        if args.order_by_index is not None:
            grp.create_dataset(name='order_by_index', data=args.order_by_index)
        grp.create_dataset(name='max_temperature', data=args.max_temperature)
        grp.create_dataset(name='downsample', data=args.downsample)
        grp.create_dataset(name='temperature', data=args.temperature)
        for key, (m, M) in bounds:
            grp.create_dataset(name=key, data=(m, M))
        for key, val in fixed.items():
            grp.create_dataset(name=key, data=val)

        # store samples
        obj.create_dataset(name='params', data=kernel._params)
        obj.create_dataset(name='samples', data=samples)
